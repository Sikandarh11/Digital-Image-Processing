{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T10:55:54.856306Z",
     "start_time": "2025-05-14T10:55:54.548517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "class LaneStateMachine:\n",
    "    def __init__(self, stabilityThreshold=5):\n",
    "        self.state = \"No Lane Detected\"\n",
    "        self.counters = defaultdict(int)\n",
    "        self.threshold = stabilityThreshold\n",
    "\n",
    "    def update(self, newState):\n",
    "        for key in self.counters:\n",
    "            if key != newState:\n",
    "                self.counters[key] = 0\n",
    "        self.counters[newState] += 1\n",
    "        if self.counters[newState] >= self.threshold:\n",
    "            if newState != self.state:\n",
    "                self.state = newState\n",
    "                for key in self.counters:\n",
    "                    self.counters[key] = 0\n",
    "        return self.state\n"
   ],
   "id": "c65ae644d3f6e23b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T11:30:54.162670Z",
     "start_time": "2025-05-14T11:30:42.727216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def calculateSlopeAngle(x1, y1, x2, y2):\n",
    "    if x2 - x1 == 0:\n",
    "        return 90\n",
    "    slope = (y2 - y1) / (x2 - x1)\n",
    "    return math.degrees(math.atan(abs(slope)))\n",
    "\n",
    "def detectLanes(frame, cropMarginPercent):\n",
    "    height, width = frame.shape[:2]\n",
    "    cropMarginX = int(width * cropMarginPercent)\n",
    "    cropMarginY = int(height * 0.3)\n",
    "    roi = frame[cropMarginY:, cropMarginX:width - cropMarginX]\n",
    "    lab = cv2.cvtColor(roi, cv2.COLOR_BGR2LAB)\n",
    "    yellowMask = cv2.inRange(lab, np.array([150, 125, 135]), np.array([255, 200, 170]))\n",
    "    kernel = np.ones((5, 3), np.uint8)\n",
    "    combinedMask = cv2.morphologyEx(yellowMask, cv2.MORPH_CLOSE, kernel)\n",
    "    combinedMask = cv2.morphologyEx(combinedMask, cv2.MORPH_OPEN, kernel)\n",
    "    maskedRoi = cv2.bitwise_and(roi, roi, mask=combinedMask)\n",
    "    gray = cv2.cvtColor(maskedRoi, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 150)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=50, maxLineGap=50)\n",
    "    return combinedMask, edges, lines, roi\n",
    "\n",
    "def classifyLaneLines(lines, cropMarginPercent, height, width, prevLeft=None, prevRight=None, angleThreshold=5, slopeThreshold=0.3):\n",
    "    leftLines = []\n",
    "    rightLines = []\n",
    "    leftAngle = None\n",
    "    rightAngle = None\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            x1 += int(cropMarginPercent * width)\n",
    "            x2 += int(cropMarginPercent * width)\n",
    "            y1 += int(height * 0.3)\n",
    "            y2 += int(height * 0.3)\n",
    "            angle = calculateSlopeAngle(x1, y1, x2, y2)\n",
    "            slope = (y2 - y1) / (x2 - x1) if (x2 - x1) != 0 else float('inf')\n",
    "\n",
    "            if 30 < angle < 90:\n",
    "                if slope < 0:\n",
    "                    leftLines.extend([(x1, y1), (x2, y2)])\n",
    "                    leftAngle = angle\n",
    "                else:\n",
    "                    rightLines.extend([(x1, y1), (x2, y2)])\n",
    "                    rightAngle = angle\n",
    "\n",
    "    if prevLeft and leftAngle is not None and prevLeft['angle'] is not None:\n",
    "        if abs(leftAngle - prevLeft['angle']) > angleThreshold:\n",
    "            leftLines = []\n",
    "\n",
    "    if prevRight and rightAngle is not None and prevRight['angle'] is not None:\n",
    "        if abs(rightAngle - prevRight['angle']) > angleThreshold:\n",
    "            rightLines = []\n",
    "\n",
    "    if not leftLines and prevLeft:\n",
    "        leftLines = prevLeft['points']\n",
    "\n",
    "    if not rightLines and prevRight:\n",
    "        rightLines = prevRight['points']\n",
    "\n",
    "    currentLeft = {\n",
    "        'points': leftLines,\n",
    "        'angle': leftAngle if leftLines else (prevLeft['angle'] if prevLeft else None),\n",
    "        'slope': (leftLines[1][0] - leftLines[0][0]) / (leftLines[1][1] - leftLines[0][1]) if len(leftLines) >= 2 else None\n",
    "    } if leftLines else None\n",
    "\n",
    "    currentRight = {\n",
    "        'points': rightLines,\n",
    "        'angle': rightAngle if rightLines else (prevRight['angle'] if prevRight else None),\n",
    "        'slope': (rightLines[1][0] - rightLines[0][0]) / (rightLines[1][1] - rightLines[0][1]) if len(rightLines) >= 2 else None\n",
    "    } if rightLines else None\n",
    "\n",
    "    return leftLines, rightLines, currentLeft, currentRight\n",
    "\n",
    "def shadeLaneRegion(frame, leftLines, rightLines):\n",
    "    height = frame.shape[0]\n",
    "    overlay = np.zeros_like(frame)\n",
    "\n",
    "    if leftLines and rightLines and len(leftLines) >= 2 and len(rightLines) >= 2:\n",
    "        leftPoints = np.array(leftLines).reshape(-1, 2)\n",
    "        rightPoints = np.array(rightLines).reshape(-1, 2)\n",
    "        leftFit = np.polyfit(leftPoints[:, 1], leftPoints[:, 0], 1)\n",
    "        rightFit = np.polyfit(rightPoints[:, 1], rightPoints[:, 0], 1)\n",
    "        plotY = np.linspace(height // 2, height - 1, num=height // 2)\n",
    "        leftX = leftFit[0] * plotY + leftFit[1]\n",
    "        rightX = rightFit[0] * plotY + rightFit[1]\n",
    "        ptsLeft = np.array([np.transpose(np.vstack([leftX, plotY]))])\n",
    "        ptsRight = np.array([np.flipud(np.transpose(np.vstack([rightX, plotY])))])\n",
    "        pts = np.hstack((ptsLeft, ptsRight)).astype(np.int32)\n",
    "        cv2.fillPoly(overlay, [pts], (0, 255, 255))\n",
    "\n",
    "    return overlay\n",
    "\n",
    "def identifyObstacles(frame):\n",
    "    hsvFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    lowerOrange = np.array([0, 45, 50])\n",
    "    upperOrange = np.array([15, 255, 255])\n",
    "    lowerBlue = np.array([90, 30, 10])\n",
    "    upperBlue = np.array([135, 255, 70])\n",
    "    orangeMask = cv2.inRange(hsvFrame, lowerOrange, upperOrange)\n",
    "    blueMask = cv2.inRange(hsvFrame, lowerBlue, upperBlue)\n",
    "    obstacleMask = cv2.bitwise_or(orangeMask, blueMask)\n",
    "    contours, _ = cv2.findContours(obstacleMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    detectedObjects = []\n",
    "    minContourArea = 500\n",
    "\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > minContourArea:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            detectedObjects.append((x, y, w, h))\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            cv2.putText(frame, \"Object\", (x, y - 8), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "    return detectedObjects\n",
    "\n",
    "def main(videoPath):\n",
    "    cap = cv2.VideoCapture(videoPath)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return\n",
    "\n",
    "    laneStateMachine = LaneStateMachine(stabilityThreshold=5)\n",
    "    cropMarginPercent = 0.1\n",
    "    prevLeft = None\n",
    "    prevRight = None\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.resize(frame, (960, 540))\n",
    "        height, width, _ = frame.shape\n",
    "        laneMask, edges, lines, laneRoi = detectLanes(frame, cropMarginPercent)\n",
    "        leftLines, rightLines, currentLeft, currentRight = classifyLaneLines(lines, cropMarginPercent, height, width, prevLeft, prevRight)\n",
    "\n",
    "        if currentLeft:\n",
    "            prevLeft = currentLeft\n",
    "        if currentRight:\n",
    "            prevRight = currentRight\n",
    "\n",
    "        laneOverlay = shadeLaneRegion(frame, leftLines, rightLines)\n",
    "\n",
    "        centerLine = None\n",
    "        if leftLines and rightLines and len(leftLines) >= 2 and len(rightLines) >= 2:\n",
    "            leftPoints = np.array(leftLines).reshape(-1, 2)\n",
    "            rightPoints = np.array(rightLines).reshape(-1, 2)\n",
    "            leftFit = np.polyfit(leftPoints[:, 1], leftPoints[:, 0], 1)\n",
    "            rightFit = np.polyfit(rightPoints[:, 1], rightPoints[:, 0], 1)\n",
    "            plotY = np.linspace(height // 2, height - 1, num=height // 2)\n",
    "            leftX = leftFit[0] * plotY + leftFit[1]\n",
    "            rightX = rightFit[0] * plotY + rightFit[1]\n",
    "            centerX = (leftX + rightX) / 2\n",
    "            centerLine = np.array([np.transpose(np.vstack([centerX, plotY]))]).astype(np.int32)\n",
    "            cv2.polylines(laneOverlay, [centerLine], False, (0, 255, 0), 2)\n",
    "\n",
    "        detectedBoxes = identifyObstacles(frame)\n",
    "\n",
    "        if not leftLines and not rightLines:\n",
    "            currentDecision = \"No Lane Detected\"\n",
    "        else:\n",
    "            currentDecision = \"Go Straight\"\n",
    "            if detectedBoxes and laneOverlay.any() and centerLine is not None:\n",
    "                laneAreaMask = cv2.cvtColor(laneOverlay, cv2.COLOR_BGR2GRAY)\n",
    "                _, laneAreaMask = cv2.threshold(laneAreaMask, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "                for (x, y, w, h) in detectedBoxes:\n",
    "                    obstacleMask = np.zeros_like(laneAreaMask)\n",
    "                    cv2.rectangle(obstacleMask, (x, y), (x + w, y + h), 255, -1)\n",
    "                    overlap = cv2.bitwise_and(laneAreaMask, obstacleMask)\n",
    "\n",
    "                    if cv2.countNonZero(overlap) > 0:\n",
    "                        obstacleCenterX = x + w // 2\n",
    "                        minDist = float('inf')\n",
    "                        closestCenterX = 0\n",
    "\n",
    "                        for point in centerLine[0]:\n",
    "                            centerX, centerY = point\n",
    "                            dist = abs(obstacleCenterX - centerX)\n",
    "                            if dist < minDist:\n",
    "                                minDist = dist\n",
    "                                closestCenterX = centerX\n",
    "\n",
    "                        if obstacleCenterX < closestCenterX:\n",
    "                            currentDecision = \"Turn RIGHT - Object on LEFT\"\n",
    "                        else:\n",
    "                            currentDecision = \"Turn LEFT - Object on RIGHT\"\n",
    "                        break\n",
    "\n",
    "        decision = laneStateMachine.update(currentDecision)\n",
    "        combinedFrame = cv2.addWeighted(frame, 0.8, laneOverlay, 0.5, 0)\n",
    "\n",
    "        if \"No Lane\" in decision:\n",
    "            textColor = (255, 255, 0)\n",
    "        elif \"STOP\" in decision or \"Turn\" in decision:\n",
    "            textColor = (0, 0, 255)\n",
    "        else:\n",
    "            textColor = (0, 255, 0)\n",
    "\n",
    "        cv2.putText(combinedFrame, f\"Decision: {decision}\", (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, textColor, 2)\n",
    "\n",
    "        for (x, y, w, h) in detectedBoxes:\n",
    "            cv2.rectangle(combinedFrame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            cv2.putText(combinedFrame, \"Object\", (x, y - 8), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)  # Updated message here\n",
    "\n",
    "        cv2.imshow(\"Lane and Object Detection\", combinedFrame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    videoPath = \"PXL_20250325_043754655.TS.mp4\"\n",
    "    main(videoPath)"
   ],
   "id": "e1c71995937c17e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leftLines :  [(np.int32(108), np.int32(513)), (np.int32(380), np.int32(241)), (np.int32(120), np.int32(538)), (np.int32(341), np.int32(292)), (np.int32(169), np.int32(451)), (np.int32(381), np.int32(239))] \n",
      "currentLeft :  {'points': [(np.int32(108), np.int32(513)), (np.int32(380), np.int32(241)), (np.int32(120), np.int32(538)), (np.int32(341), np.int32(292)), (np.int32(169), np.int32(451)), (np.int32(381), np.int32(239))], 'angle': 45.0, 'slope': np.float64(-1.0)}\n",
      "leftLines :  [(np.int32(120), np.int32(500)), (np.int32(382), np.int32(238)), (np.int32(181), np.int32(470)), (np.int32(341), np.int32(292)), (np.int32(98), np.int32(524)), (np.int32(162), np.int32(460)), (np.int32(121), np.int32(538)), (np.int32(230), np.int32(417)), (np.int32(215), np.int32(404)), (np.int32(380), np.int32(239)), (np.int32(235), np.int32(409)), (np.int32(383), np.int32(244)), (np.int32(96), np.int32(525)), (np.int32(214), np.int32(407))] \n",
      "currentLeft :  {'points': [(np.int32(120), np.int32(500)), (np.int32(382), np.int32(238)), (np.int32(181), np.int32(470)), (np.int32(341), np.int32(292)), (np.int32(98), np.int32(524)), (np.int32(162), np.int32(460)), (np.int32(121), np.int32(538)), (np.int32(230), np.int32(417)), (np.int32(215), np.int32(404)), (np.int32(380), np.int32(239)), (np.int32(235), np.int32(409)), (np.int32(383), np.int32(244)), (np.int32(96), np.int32(525)), (np.int32(214), np.int32(407))], 'angle': 45.0, 'slope': np.float64(-1.0)}\n",
      "leftLines :  [(np.int32(119), np.int32(501)), (np.int32(381), np.int32(239)), (np.int32(186), np.int32(464)), (np.int32(359), np.int32(271)), (np.int32(190), np.int32(429)), (np.int32(379), np.int32(240)), (np.int32(96), np.int32(525)), (np.int32(206), np.int32(415)), (np.int32(121), np.int32(538)), (np.int32(227), np.int32(420))] \n",
      "currentLeft :  {'points': [(np.int32(119), np.int32(501)), (np.int32(381), np.int32(239)), (np.int32(186), np.int32(464)), (np.int32(359), np.int32(271)), (np.int32(190), np.int32(429)), (np.int32(379), np.int32(240)), (np.int32(96), np.int32(525)), (np.int32(206), np.int32(415)), (np.int32(121), np.int32(538)), (np.int32(227), np.int32(420))], 'angle': 48.0664855011259, 'slope': np.float64(-1.0)}\n",
      "leftLines :  [(np.int32(185), np.int32(465)), (np.int32(366), np.int32(263)), (np.int32(115), np.int32(505)), (np.int32(379), np.int32(241)), (np.int32(190), np.int32(429)), (np.int32(378), np.int32(241)), (np.int32(121), np.int32(538)), (np.int32(234), np.int32(412)), (np.int32(96), np.int32(525)), (np.int32(206), np.int32(415))] \n",
      "currentLeft :  {'points': [(np.int32(185), np.int32(465)), (np.int32(366), np.int32(263)), (np.int32(115), np.int32(505)), (np.int32(379), np.int32(241)), (np.int32(190), np.int32(429)), (np.int32(378), np.int32(241)), (np.int32(121), np.int32(538)), (np.int32(234), np.int32(412)), (np.int32(96), np.int32(525)), (np.int32(206), np.int32(415))], 'angle': 45.0, 'slope': np.float64(-0.8960396039603961)}\n",
      "leftLines :  [(np.int32(326), np.int32(292)), (np.int32(376), np.int32(242)), (np.int32(119), np.int32(538)), (np.int32(340), np.int32(293)), (np.int32(149), np.int32(470)), (np.int32(378), np.int32(241)), (np.int32(214), np.int32(432)), (np.int32(381), np.int32(246)), (np.int32(109), np.int32(511)), (np.int32(379), np.int32(241)), (np.int32(120), np.int32(538)), (np.int32(237), np.int32(408))] \n",
      "currentLeft :  {'points': [(np.int32(326), np.int32(292)), (np.int32(376), np.int32(242)), (np.int32(119), np.int32(538)), (np.int32(340), np.int32(293)), (np.int32(149), np.int32(470)), (np.int32(378), np.int32(241)), (np.int32(214), np.int32(432)), (np.int32(381), np.int32(246)), (np.int32(109), np.int32(511)), (np.int32(379), np.int32(241)), (np.int32(120), np.int32(538)), (np.int32(237), np.int32(408))], 'angle': 48.01278750418334, 'slope': np.float64(-1.0)}\n",
      "leftLines :  [(np.int32(148), np.int32(471)), (np.int32(384), np.int32(235)), (np.int32(120), np.int32(538)), (np.int32(340), np.int32(293)), (np.int32(222), np.int32(423)), (np.int32(385), np.int32(241)), (np.int32(96), np.int32(524)), (np.int32(322), np.int32(298))] \n",
      "currentLeft :  {'points': [(np.int32(148), np.int32(471)), (np.int32(384), np.int32(235)), (np.int32(120), np.int32(538)), (np.int32(340), np.int32(293)), (np.int32(222), np.int32(423)), (np.int32(385), np.int32(241)), (np.int32(96), np.int32(524)), (np.int32(322), np.int32(298))], 'angle': 45.0, 'slope': np.float64(-1.0)}\n",
      "leftLines :  [(np.int32(147), np.int32(471)), (np.int32(378), np.int32(240)), (np.int32(118), np.int32(538)), (np.int32(340), np.int32(292)), (np.int32(120), np.int32(538)), (np.int32(231), np.int32(414)), (np.int32(232), np.int32(411)), (np.int32(381), np.int32(245))] \n",
      "currentLeft :  {'points': [(np.int32(147), np.int32(471)), (np.int32(378), np.int32(240)), (np.int32(118), np.int32(538)), (np.int32(340), np.int32(292)), (np.int32(120), np.int32(538)), (np.int32(231), np.int32(414)), (np.int32(232), np.int32(411)), (np.int32(381), np.int32(245))], 'angle': 48.08915637533654, 'slope': np.float64(-1.0)}\n",
      "leftLines :  [(np.int32(102), np.int32(516)), (np.int32(379), np.int32(239)), (np.int32(146), np.int32(471)), (np.int32(378), np.int32(239)), (np.int32(118), np.int32(538)), (np.int32(339), np.int32(292)), (np.int32(175), np.int32(474)), (np.int32(344), np.int32(286))] \n",
      "currentLeft :  {'points': [(np.int32(102), np.int32(516)), (np.int32(379), np.int32(239)), (np.int32(146), np.int32(471)), (np.int32(378), np.int32(239)), (np.int32(118), np.int32(538)), (np.int32(339), np.int32(292)), (np.int32(175), np.int32(474)), (np.int32(344), np.int32(286))], 'angle': 48.046480990163026, 'slope': np.float64(-1.0)}\n",
      "leftLines :  [(np.int32(103), np.int32(514)), (np.int32(382), np.int32(235)), (np.int32(117), np.int32(538)), (np.int32(341), np.int32(289)), (np.int32(147), np.int32(469)), (np.int32(380), np.int32(236)), (np.int32(233), np.int32(408)), (np.int32(383), np.int32(241)), (np.int32(96), np.int32(522)), (np.int32(186), np.int32(432)), (np.int32(118), np.int32(538)), (np.int32(241), np.int32(401))] \n",
      "currentLeft :  {'points': [(np.int32(103), np.int32(514)), (np.int32(382), np.int32(235)), (np.int32(117), np.int32(538)), (np.int32(341), np.int32(289)), (np.int32(147), np.int32(469)), (np.int32(380), np.int32(236)), (np.int32(233), np.int32(408)), (np.int32(383), np.int32(241)), (np.int32(96), np.int32(522)), (np.int32(186), np.int32(432)), (np.int32(118), np.int32(538)), (np.int32(241), np.int32(401))], 'angle': 48.082180824528145, 'slope': np.float64(-1.0)}\n",
      "leftLines :  [(np.int32(101), np.int32(515)), (np.int32(382), np.int32(234)), (np.int32(116), np.int32(538)), (np.int32(355), np.int32(272)), (np.int32(145), np.int32(470)), (np.int32(380), np.int32(235))] \n",
      "currentLeft :  {'points': [(np.int32(101), np.int32(515)), (np.int32(382), np.int32(234)), (np.int32(116), np.int32(538)), (np.int32(355), np.int32(272)), (np.int32(145), np.int32(470)), (np.int32(380), np.int32(235))], 'angle': 45.0, 'slope': np.float64(-1.0)}\n",
      "leftLines :  [(np.int32(116), np.int32(538)), (np.int32(338), np.int32(291)), (np.int32(107), np.int32(508)), (np.int32(373), np.int32(242)), (np.int32(96), np.int32(520)), (np.int32(380), np.int32(236)), (np.int32(185), np.int32(460)), (np.int32(363), np.int32(262))] \n",
      "currentLeft :  {'points': [(np.int32(116), np.int32(538)), (np.int32(338), np.int32(291)), (np.int32(107), np.int32(508)), (np.int32(373), np.int32(242)), (np.int32(96), np.int32(520)), (np.int32(380), np.int32(236)), (np.int32(185), np.int32(460)), (np.int32(363), np.int32(262))], 'angle': 48.04477844419399, 'slope': np.float64(-0.8987854251012146)}\n",
      "leftLines :  [(np.int32(140), np.int32(474)), (np.int32(378), np.int32(236)), (np.int32(115), np.int32(538)), (np.int32(339), np.int32(289)), (np.int32(239), np.int32(399)), (np.int32(381), np.int32(241)), (np.int32(98), np.int32(517)), (np.int32(380), np.int32(235))] \n",
      "currentLeft :  {'points': [(np.int32(140), np.int32(474)), (np.int32(378), np.int32(236)), (np.int32(115), np.int32(538)), (np.int32(339), np.int32(289)), (np.int32(239), np.int32(399)), (np.int32(381), np.int32(241)), (np.int32(98), np.int32(517)), (np.int32(380), np.int32(235))], 'angle': 45.0, 'slope': np.float64(-1.0)}\n",
      "leftLines :  [(np.int32(96), np.int32(519)), (np.int32(373), np.int32(242)), (np.int32(168), np.int32(479)), (np.int32(337), np.int32(291))] \n",
      "currentLeft :  {'points': [(np.int32(96), np.int32(519)), (np.int32(373), np.int32(242)), (np.int32(168), np.int32(479)), (np.int32(337), np.int32(291))], 'angle': 48.046480990163026, 'slope': np.float64(-1.0)}\n",
      "leftLines :  [(np.int32(137), np.int32(477)), (np.int32(378), np.int32(236)), (np.int32(136), np.int32(517)), (np.int32(282), np.int32(350)), (np.int32(182), np.int32(431)), (np.int32(374), np.int32(239)), (np.int32(257), np.int32(380)), (np.int32(377), np.int32(243))] \n",
      "currentLeft :  {'points': [(np.int32(137), np.int32(477)), (np.int32(378), np.int32(236)), (np.int32(136), np.int32(517)), (np.int32(282), np.int32(350)), (np.int32(182), np.int32(431)), (np.int32(374), np.int32(239)), (np.int32(257), np.int32(380)), (np.int32(377), np.int32(243))], 'angle': 48.78447990948791, 'slope': np.float64(-1.0)}\n",
      "leftLines :  [(np.int32(119), np.int32(537)), (np.int32(298), np.int32(332)), (np.int32(116), np.int32(499)), (np.int32(211), np.int32(404)), (np.int32(205), np.int32(408)), (np.int32(379), np.int32(234)), (np.int32(202), np.int32(443)), (np.int32(381), np.int32(238)), (np.int32(170), np.int32(444)), (np.int32(371), np.int32(243))] \n",
      "currentLeft :  {'points': [(np.int32(119), np.int32(537)), (np.int32(298), np.int32(332)), (np.int32(116), np.int32(499)), (np.int32(211), np.int32(404)), (np.int32(205), np.int32(408)), (np.int32(379), np.int32(234)), (np.int32(202), np.int32(443)), (np.int32(381), np.int32(238)), (np.int32(170), np.int32(444)), (np.int32(371), np.int32(243))], 'angle': 45.0, 'slope': np.float64(-0.8731707317073171)}\n",
      "leftLines :  [(np.int32(119), np.int32(538)), (np.int32(380), np.int32(238)), (np.int32(180), np.int32(434)), (np.int32(369), np.int32(245)), (np.int32(97), np.int32(520)), (np.int32(173), np.int32(442))] \n",
      "currentLeft :  {'points': [(np.int32(119), np.int32(538)), (np.int32(380), np.int32(238)), (np.int32(180), np.int32(434)), (np.int32(369), np.int32(245)), (np.int32(97), np.int32(520)), (np.int32(173), np.int32(442))], 'angle': 45.744059202888714, 'slope': np.float64(-0.87)}\n",
      "leftLines :  [(np.int32(120), np.int32(538)), (np.int32(360), np.int32(262)), (np.int32(119), np.int32(538)), (np.int32(377), np.int32(241)), (np.int32(98), np.int32(521)), (np.int32(347), np.int32(264)), (np.int32(264), np.int32(351)), (np.int32(375), np.int32(237)), (np.int32(98), np.int32(520)), (np.int32(256), np.int32(357))] \n",
      "currentLeft :  {'points': [(np.int32(120), np.int32(538)), (np.int32(360), np.int32(262)), (np.int32(119), np.int32(538)), (np.int32(377), np.int32(241)), (np.int32(98), np.int32(521)), (np.int32(347), np.int32(264)), (np.int32(264), np.int32(351)), (np.int32(375), np.int32(237)), (np.int32(98), np.int32(520)), (np.int32(256), np.int32(357))], 'angle': 45.89238545874055, 'slope': np.float64(-0.8695652173913043)}\n",
      "leftLines :  [(np.int32(120), np.int32(538)), (np.int32(377), np.int32(242)), (np.int32(97), np.int32(524)), (np.int32(374), np.int32(237)), (np.int32(98), np.int32(521)), (np.int32(318), np.int32(294)), (np.int32(227), np.int32(414)), (np.int32(377), np.int32(241))] \n",
      "currentLeft :  {'points': [(np.int32(120), np.int32(538)), (np.int32(377), np.int32(242)), (np.int32(97), np.int32(524)), (np.int32(374), np.int32(237)), (np.int32(98), np.int32(521)), (np.int32(318), np.int32(294)), (np.int32(227), np.int32(414)), (np.int32(377), np.int32(241))], 'angle': 49.073010448052216, 'slope': np.float64(-0.8682432432432432)}\n",
      "leftLines :  [(np.int32(96), np.int32(524)), (np.int32(372), np.int32(239)), (np.int32(176), np.int32(474)), (np.int32(378), np.int32(241)), (np.int32(121), np.int32(538)), (np.int32(333), np.int32(294)), (np.int32(107), np.int32(514)), (np.int32(196), np.int32(422))] \n",
      "currentLeft :  {'points': [(np.int32(96), np.int32(524)), (np.int32(372), np.int32(239)), (np.int32(176), np.int32(474)), (np.int32(378), np.int32(241)), (np.int32(121), np.int32(538)), (np.int32(333), np.int32(294)), (np.int32(107), np.int32(514)), (np.int32(196), np.int32(422))], 'angle': 45.94956685643583, 'slope': np.float64(-0.968421052631579)}\n",
      "leftLines :  [(np.int32(96), np.int32(525)), (np.int32(372), np.int32(239)), (np.int32(211), np.int32(434)), (np.int32(357), np.int32(265)), (np.int32(121), np.int32(538)), (np.int32(328), np.int32(300))] \n",
      "currentLeft :  {'points': [(np.int32(96), np.int32(525)), (np.int32(372), np.int32(239)), (np.int32(211), np.int32(434)), (np.int32(357), np.int32(265)), (np.int32(121), np.int32(538)), (np.int32(328), np.int32(300))], 'angle': 48.98495347919674, 'slope': np.float64(-0.965034965034965)}\n",
      "leftLines :  [(np.int32(96), np.int32(524)), (np.int32(373), np.int32(237)), (np.int32(198), np.int32(449)), (np.int32(333), np.int32(293)), (np.int32(122), np.int32(538)), (np.int32(221), np.int32(424))] \n",
      "currentLeft :  {'points': [(np.int32(96), np.int32(524)), (np.int32(373), np.int32(237)), (np.int32(198), np.int32(449)), (np.int32(333), np.int32(293)), (np.int32(122), np.int32(538)), (np.int32(221), np.int32(424))], 'angle': 49.028263666485145, 'slope': np.float64(-0.9651567944250871)}\n",
      "leftLines :  [(np.int32(106), np.int32(514)), (np.int32(371), np.int32(239)), (np.int32(124), np.int32(538)), (np.int32(289), np.int32(342)), (np.int32(270), np.int32(366)), (np.int32(374), np.int32(243))] \n",
      "currentLeft :  {'points': [(np.int32(106), np.int32(514)), (np.int32(371), np.int32(239)), (np.int32(124), np.int32(538)), (np.int32(289), np.int32(342)), (np.int32(270), np.int32(366)), (np.int32(374), np.int32(243))], 'angle': 49.78452968816502, 'slope': np.float64(-0.9636363636363636)}\n",
      "leftLines :  [(np.int32(117), np.int32(502)), (np.int32(370), np.int32(240)), (np.int32(271), np.int32(364)), (np.int32(373), np.int32(243)), (np.int32(122), np.int32(538)), (np.int32(240), np.int32(398)), (np.int32(146), np.int32(511)), (np.int32(372), np.int32(242)), (np.int32(170), np.int32(446)), (np.int32(367), np.int32(242)), (np.int32(98), np.int32(523)), (np.int32(169), np.int32(449))] \n",
      "currentLeft :  {'points': [(np.int32(117), np.int32(502)), (np.int32(370), np.int32(240)), (np.int32(271), np.int32(364)), (np.int32(373), np.int32(243)), (np.int32(122), np.int32(538)), (np.int32(240), np.int32(398)), (np.int32(146), np.int32(511)), (np.int32(372), np.int32(242)), (np.int32(170), np.int32(446)), (np.int32(367), np.int32(242)), (np.int32(98), np.int32(523)), (np.int32(169), np.int32(449))], 'angle': 46.185260818622396, 'slope': np.float64(-0.9656488549618321)}\n",
      "leftLines :  [(np.int32(169), np.int32(446)), (np.int32(369), np.int32(239)), (np.int32(96), np.int32(523)), (np.int32(312), np.int32(299)), (np.int32(136), np.int32(522)), (np.int32(372), np.int32(241)), (np.int32(215), np.int32(429)), (np.int32(372), np.int32(243))] \n",
      "currentLeft :  {'points': [(np.int32(169), np.int32(446)), (np.int32(369), np.int32(239)), (np.int32(96), np.int32(523)), (np.int32(312), np.int32(299)), (np.int32(136), np.int32(522)), (np.int32(372), np.int32(241)), (np.int32(215), np.int32(429)), (np.int32(372), np.int32(243))], 'angle': 49.832755987134945, 'slope': np.float64(-0.966183574879227)}\n",
      "leftLines :  [(np.int32(117), np.int32(500)), (np.int32(370), np.int32(238)), (np.int32(130), np.int32(528)), (np.int32(286), np.int32(343)), (np.int32(195), np.int32(452)), (np.int32(372), np.int32(241))] \n",
      "currentLeft :  {'points': [(np.int32(117), np.int32(500)), (np.int32(370), np.int32(238)), (np.int32(130), np.int32(528)), (np.int32(286), np.int32(343)), (np.int32(195), np.int32(452)), (np.int32(372), np.int32(241))], 'angle': 50.007971892040274, 'slope': np.float64(-0.9656488549618321)}\n",
      "leftLines :  [(np.int32(96), np.int32(522)), (np.int32(370), np.int32(238)), (np.int32(171), np.int32(443)), (np.int32(368), np.int32(239)), (np.int32(184), np.int32(464)), (np.int32(372), np.int32(241)), (np.int32(122), np.int32(536)), (np.int32(263), np.int32(369))] \n",
      "currentLeft :  {'points': [(np.int32(96), np.int32(522)), (np.int32(370), np.int32(238)), (np.int32(171), np.int32(443)), (np.int32(368), np.int32(239)), (np.int32(184), np.int32(464)), (np.int32(372), np.int32(241)), (np.int32(122), np.int32(536)), (np.int32(263), np.int32(369))], 'angle': 49.825216927109814, 'slope': np.float64(-0.9647887323943662)}\n",
      "leftLines :  [(np.int32(181), np.int32(432)), (np.int32(368), np.int32(238)), (np.int32(192), np.int32(454)), (np.int32(372), np.int32(240)), (np.int32(96), np.int32(522)), (np.int32(303), np.int32(307)), (np.int32(120), np.int32(538)), (np.int32(253), np.int32(380))] \n",
      "currentLeft :  {'points': [(np.int32(181), np.int32(432)), (np.int32(368), np.int32(238)), (np.int32(192), np.int32(454)), (np.int32(372), np.int32(240)), (np.int32(96), np.int32(522)), (np.int32(303), np.int32(307)), (np.int32(120), np.int32(538)), (np.int32(253), np.int32(380))], 'angle': 49.91026122158257, 'slope': np.float64(-0.9639175257731959)}\n",
      "leftLines :  [(np.int32(96), np.int32(521)), (np.int32(276), np.int32(335)), (np.int32(113), np.int32(502)), (np.int32(370), np.int32(236)), (np.int32(137), np.int32(518)), (np.int32(372), np.int32(239)), (np.int32(264), np.int32(369)), (np.int32(372), np.int32(240))] \n",
      "currentLeft :  {'points': [(np.int32(96), np.int32(521)), (np.int32(276), np.int32(335)), (np.int32(113), np.int32(502)), (np.int32(370), np.int32(236)), (np.int32(137), np.int32(518)), (np.int32(372), np.int32(239)), (np.int32(264), np.int32(369)), (np.int32(372), np.int32(240))], 'angle': 50.063616853030084, 'slope': np.float64(-0.967741935483871)}\n",
      "leftLines :  [(np.int32(110), np.int32(504)), (np.int32(368), np.int32(237)), (np.int32(116), np.int32(538)), (np.int32(315), np.int32(309)), (np.int32(210), np.int32(429)), (np.int32(349), np.int32(268)), (np.int32(96), np.int32(520)), (np.int32(370), np.int32(236))] \n",
      "currentLeft :  {'points': [(np.int32(110), np.int32(504)), (np.int32(368), np.int32(237)), (np.int32(116), np.int32(538)), (np.int32(315), np.int32(309)), (np.int32(210), np.int32(429)), (np.int32(349), np.int32(268)), (np.int32(96), np.int32(520)), (np.int32(370), np.int32(236))], 'angle': 46.026696180057876, 'slope': np.float64(-0.9662921348314607)}\n",
      "leftLines :  [(np.int32(96), np.int32(518)), (np.int32(367), np.int32(238)), (np.int32(115), np.int32(538)), (np.int32(314), np.int32(309)), (np.int32(208), np.int32(430)), (np.int32(351), np.int32(265))] \n",
      "currentLeft :  {'points': [(np.int32(96), np.int32(518)), (np.int32(367), np.int32(238)), (np.int32(115), np.int32(538)), (np.int32(314), np.int32(309)), (np.int32(208), np.int32(430)), (np.int32(351), np.int32(265))], 'angle': 49.08561677997487, 'slope': np.float64(-0.9678571428571429)}\n",
      "leftLines :  [(np.int32(96), np.int32(517)), (np.int32(354), np.int32(250)), (np.int32(113), np.int32(538)), (np.int32(350), np.int32(265))] \n",
      "currentLeft :  {'points': [(np.int32(96), np.int32(517)), (np.int32(354), np.int32(250)), (np.int32(113), np.int32(538)), (np.int32(350), np.int32(265))], 'angle': 49.03771062097712, 'slope': np.float64(-0.9662921348314607)}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 219\u001B[39m\n\u001B[32m    217\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[34m__name__\u001B[39m == \u001B[33m\"\u001B[39m\u001B[33m__main__\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    218\u001B[39m     videoPath = \u001B[33m\"\u001B[39m\u001B[33mPXL_20250325_043754655.TS.mp4\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m219\u001B[39m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvideoPath\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 164\u001B[39m, in \u001B[36mmain\u001B[39m\u001B[34m(videoPath)\u001B[39m\n\u001B[32m    162\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    163\u001B[39m     currentDecision = \u001B[33m\"\u001B[39m\u001B[33mGo Straight\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m164\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m detectedBoxes \u001B[38;5;129;01mand\u001B[39;00m \u001B[43mlaneOverlay\u001B[49m\u001B[43m.\u001B[49m\u001B[43many\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mand\u001B[39;00m centerLine \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    165\u001B[39m         laneAreaMask = cv2.cvtColor(laneOverlay, cv2.COLOR_BGR2GRAY)\n\u001B[32m    166\u001B[39m         _, laneAreaMask = cv2.threshold(laneAreaMask, \u001B[32m1\u001B[39m, \u001B[32m255\u001B[39m, cv2.THRESH_BINARY)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\2. DIP\\2. LAB\\pythonProject\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:64\u001B[39m, in \u001B[36m_any\u001B[39m\u001B[34m(a, axis, dtype, out, keepdims, where)\u001B[39m\n\u001B[32m     62\u001B[39m \u001B[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001B[39;00m\n\u001B[32m     63\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m where \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m64\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mumr_any\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     65\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m umr_any(a, axis, dtype, out, keepdims, where=where)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d26b89bcce9b4417"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ed0246516193eb23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "994d269220363425"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "97cf37eccf4d4a86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1991fc5e387d795b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b9b8252e1251a102"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3db23c4cd2b859e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5599c3a874db35bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "159f669358eece37"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cd16fe391a16023b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c718fb185dd46452"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ba758921893cef93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8fa752caec26df2a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "298f926dae9a2263"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e099de29eaedb4b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a995b2fde38da594"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7d245a7b8ff81518"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "655e68ac5ab86695"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bbd4baf7c904bedf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7655af1ba1b04f7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "36ca90ca80cd2fc6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d1e3b97cf26316a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2f16353c2240ed4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6b62887a329949b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T18:00:10.942034Z",
     "start_time": "2025-05-12T17:59:13.389167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def fixColor(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    cv2.fillPoly(mask, vertices, 255)\n",
    "    masked_img = cv2.bitwise_and(img, mask)\n",
    "    return masked_img\n",
    "\n",
    "video_path = \"PXL_20250325_043754655.TS.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "\n",
    "backSub = cv2.createBackgroundSubtractorMOG2(detectShadows=False)\n",
    "imshape = (600,600)\n",
    "mask_roi = np.zeros(imshape, dtype=np.uint8)\n",
    "ignore_mask_color = 255\n",
    "\n",
    "vertices = np.array([[\n",
    "    (0, imshape[0]),\n",
    "    (int(imshape[1] * .20), int(imshape[0] * .4)),\n",
    "    (int(imshape[1] * .80), int(imshape[0] * .4)),\n",
    "    (imshape[1], imshape[0])\n",
    "]], dtype=np.int32)\n",
    "\n",
    "mask_roi = cv2.fillPoly(mask_roi, vertices, ignore_mask_color)\n",
    "\n",
    "mask = np.zeros(imshape)\n",
    "\n",
    "vertices = np.array([\n",
    "    [\n",
    "        (imshape[1]*0.2,imshape[0]),\n",
    "        (imshape[1] * .45, imshape[0] * .7),\n",
    "        (imshape[1] * .55, imshape[0] * .7),\n",
    "        (imshape[1]*0.8,imshape[0])\n",
    "    ]\n",
    "], dtype=np.int32)\n",
    "\n",
    "mask_obj = cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "print(mask_obj.shape)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Stream ended\")\n",
    "        break\n",
    "\n",
    "    image = cv2.resize(frame, (600, 600))\n",
    "\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    lower_yellow = np.array([15, 40, 60])\n",
    "    upper_yellow = np.array([35, 255, 255])\n",
    "\n",
    "    lower_white = np.array([0, 0, 200])\n",
    "    upper_white = np.array([180, 5, 255])\n",
    "\n",
    "    yellow_mask = cv2.inRange(hsv_image, lower_yellow, upper_yellow)\n",
    "    white_mask = cv2.inRange(hsv_image, lower_white, upper_white)\n",
    "    mask = cv2.bitwise_or(yellow_mask, white_mask)\n",
    "\n",
    "    median = cv2.medianBlur(mask, 5)\n",
    "    blur = cv2.GaussianBlur(median, (5, 5), 0)\n",
    "\n",
    "    edges = cv2.Canny(blur, 50, 150)\n",
    "    print(edges.shape)\n",
    "    masked_edges = cv2.bitwise_and(edges, mask_roi)\n",
    "\n",
    "    roi = cv2.bitwise_and(edges, edges, mask=mask_roi.astype(np.uint8))\n",
    "    croppedregion = cv2.bitwise_and(image, image, mask=mask_obj.astype(np.uint8))\n",
    "\n",
    "    fg_mask = backSub.apply(croppedregion)\n",
    "\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_DILATE, kernel)\n",
    "\n",
    "    non_zero = np.count_nonzero(fg_mask)\n",
    "\n",
    "    if non_zero > 1200:\n",
    "        print(\"Obstacle Detected!\")\n",
    "    else:\n",
    "        print(\"No Obstacle.\")\n",
    "\n",
    "\n",
    "\n",
    "    lines = cv2.HoughLinesP(roi, rho=2, theta=np.pi/180, threshold=30, minLineLength=20, maxLineGap=1)\n",
    "    cv2.imshow('', fg_mask)\n",
    "    mxb = np.array([[0, 0]])\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                if x2 - x1 == 0:\n",
    "                    continue  # Avoid division by zero\n",
    "                m = (y2 - y1) / (x2 - x1)\n",
    "                b = y1 - m * x1\n",
    "                mxb = np.vstack((mxb, [m, b]))\n",
    "\n",
    "\n",
    "        if mxb.shape[0] > 1:\n",
    "            median_right_m = np.median(mxb[mxb[:, 0] > 0, 0])\n",
    "            median_left_m = np.median(mxb[mxb[:, 0] < 0, 0])\n",
    "            median_right_b = np.median(mxb[mxb[:, 0] > 0, 1])\n",
    "            median_left_b = np.median(mxb[mxb[:, 0] < 0, 1])\n",
    "\n",
    "            if not np.isnan(median_right_m) and not np.isnan(median_left_m):\n",
    "                x_intersect = (median_left_b - median_right_b) / (median_right_m - median_left_m)\n",
    "                y_intersect = median_right_m * x_intersect + median_right_b\n",
    "\n",
    "                left_bottom = (imshape[0] - median_left_b) / median_left_m\n",
    "                right_bottom = (imshape[0] - median_right_b) / median_right_m\n",
    "\n",
    "                line_image = np.copy(image) * 0\n",
    "                cv2.line(\n",
    "                    line_image,\n",
    "                    (int(left_bottom), imshape[0]),\n",
    "                    (int(x_intersect), int(y_intersect)),\n",
    "                    (255, 0, 0), 10\n",
    "                )\n",
    "                cv2.line(\n",
    "                    line_image,\n",
    "                    (int(right_bottom), imshape[0]),\n",
    "                    (int(x_intersect), int(y_intersect)),\n",
    "                    (0, 0, 255), 10\n",
    "                )\n",
    "\n",
    "                lane_edges = cv2.addWeighted(image, 0.8, line_image, 1, 0)\n",
    "            else:\n",
    "                lane_edges = image\n",
    "        else:\n",
    "            lane_edges = image\n",
    "    else:\n",
    "        lane_edges = image\n",
    "    cv2.polylines(lane_edges, [vertices], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "    cv2.imshow('Road Detection', lane_edges)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "32174b7ad8d34b16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 600)\n",
      "(600, 600)\n",
      "Obstacle Detected!\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n",
      "(600, 600)\n",
      "No Obstacle.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-10T19:16:33.031127Z",
     "start_time": "2025-05-10T19:16:16.221962Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# -------------------- Lane State Machine Class --------------------\n",
    "\n",
    "class LaneStateMachine:\n",
    "    def __init__(self, stability_threshold=5):\n",
    "        self.state = \"No Lane Detected\"\n",
    "        self.counters = defaultdict(int)\n",
    "        self.threshold = stability_threshold\n",
    "\n",
    "    def update(self, new_state):\n",
    "        for key in self.counters:\n",
    "            if key != new_state:\n",
    "                self.counters[key] = 0\n",
    "        self.counters[new_state] += 1\n",
    "\n",
    "        if self.counters[new_state] >= self.threshold:\n",
    "            if new_state != self.state:\n",
    "                self.state = new_state\n",
    "                for key in self.counters:\n",
    "                    self.counters[key] = 0\n",
    "        return self.state\n",
    "\n",
    "# -------------------- Utility Functions --------------------\n",
    "\n",
    "def is_dashed(lines, threshold=20):\n",
    "    if len(lines) < 4:\n",
    "        return False\n",
    "    lines = sorted(lines, key=lambda p: p[1])\n",
    "    gaps = [abs(lines[i + 2][1] - lines[i][1]) for i in range(0, len(lines) - 2, 2)]\n",
    "    return sum(gaps) / len(gaps) > threshold if gaps else False\n",
    "\n",
    "def apply_clahe(image):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    cl = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8)).apply(l)\n",
    "    return cv2.cvtColor(cv2.merge((cl, a, b)), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "\n",
    "def detect_lanes(frame, crop_margin):\n",
    "    height, width = frame.shape[:2]\n",
    "    roi = frame[height // 2:, crop_margin:width - crop_margin]\n",
    "\n",
    "    # Apply CLAHE for contrast enhancement\n",
    "    clahe_roi = apply_clahe(roi)\n",
    "\n",
    "    # HSV yellow mask with tightened thresholds to reduce grass\n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    # Bright yellow filtering\n",
    "    hsv_yellow_mask = cv2.inRange(hsv, np.array([20, 100, 100]), np.array([35, 255, 255]))\n",
    "    v_mask = cv2.inRange(v, 150, 255)\n",
    "    hsv_yellow_mask = cv2.bitwise_and(hsv_yellow_mask, hsv_yellow_mask, mask=v_mask)\n",
    "\n",
    "    # LAB yellow mask (optional but helps in poor lighting)\n",
    "    lab = cv2.cvtColor(roi, cv2.COLOR_BGR2LAB)\n",
    "    lab_yellow_mask = cv2.inRange(lab, np.array([150, 120, 120]), np.array([255, 160, 160]))\n",
    "\n",
    "    # Combine HSV + LAB masks\n",
    "    combined_mask = cv2.bitwise_or(hsv_yellow_mask, lab_yellow_mask)\n",
    "\n",
    "    # Morphological filtering to suppress grass textures\n",
    "    kernel = np.ones((7, 7), np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Edge detection on masked bright yellow lane area\n",
    "    masked_roi = cv2.bitwise_and(clahe_roi, clahe_roi, mask=combined_mask)\n",
    "    gray = cv2.cvtColor(masked_roi, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blur, 100, 200)\n",
    "    edges = cv2.bitwise_and(edges, combined_mask)\n",
    "\n",
    "    # Detect lines\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=50, minLineLength=50, maxLineGap=30)\n",
    "    return combined_mask, edges, lines, roi\n",
    "\n",
    "\n",
    "def classify_lane_lines(lines, crop_margin, height):\n",
    "    left_lines, right_lines = [], []\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            x1 += crop_margin\n",
    "            x2 += crop_margin\n",
    "            y1 += height // 2\n",
    "            y2 += height // 2\n",
    "\n",
    "            if x2 - x1 == 0:\n",
    "                continue\n",
    "\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "            angle = np.degrees(np.arctan(abs(slope)))\n",
    "\n",
    "            # Only consider lines within specific angle ranges\n",
    "            if 30 < angle < 80:  # Typical lane angles\n",
    "                if slope < 0:\n",
    "                    left_lines.extend([(x1, y1), (x2, y2)])\n",
    "                else:\n",
    "                    right_lines.extend([(x1, y1), (x2, y2)])\n",
    "    return left_lines, right_lines\n",
    "\n",
    "def draw_lane_lines(frame, left_lines, right_lines):\n",
    "    height = frame.shape[0]\n",
    "    plot_y = np.linspace(height // 2, height - 1, num=height // 2)\n",
    "    line_image = np.zeros_like(frame)\n",
    "\n",
    "    def draw_line(points, color):\n",
    "        if points:\n",
    "            points_np = np.array(points)\n",
    "            fit = np.polyfit(points_np[:, 1], points_np[:, 0], 1)\n",
    "            x_vals = fit[0] * plot_y + fit[1]\n",
    "            for x, y in zip(x_vals, plot_y):\n",
    "                cv2.circle(line_image, (int(x), int(y)), 2, color, -1)\n",
    "\n",
    "    draw_line(left_lines, (255, 0, 0))\n",
    "    draw_line(right_lines, (0, 0, 255))\n",
    "    return line_image\n",
    "\n",
    "def detect_obstacles(frame, obstacle_crop_margin):\n",
    "    height, width = frame.shape[:2]\n",
    "    hsv = cv2.cvtColor(frame[:, obstacle_crop_margin:width - obstacle_crop_margin], cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    color_ranges = [\n",
    "        (np.array([0, 0, 0]), np.array([180, 255, 50]), 'Black'),\n",
    "        (np.array([90, 50, 50]), np.array([130, 255, 255]), 'Blue'),\n",
    "        (np.array([0, 70, 50]), np.array([10, 255, 255]), 'Red'),\n",
    "        (np.array([160, 70, 50]), np.array([180, 255, 255]), 'Red')\n",
    "    ]\n",
    "\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    combined_mask = np.zeros_like(hsv[:, :, 0])\n",
    "    color_mask_map = []\n",
    "\n",
    "    for lower, upper, color_name in color_ranges:\n",
    "        mask = cv2.inRange(hsv, lower, upper)\n",
    "        color_mask_map.append((mask, color_name))\n",
    "        combined_mask = cv2.bitwise_or(combined_mask, mask)\n",
    "\n",
    "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if 500 < area < 750:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            center_x_global = x + w // 2 + obstacle_crop_margin\n",
    "            if width // 4 < center_x_global < 3 * width // 4:\n",
    "                mask_roi = np.zeros_like(combined_mask)\n",
    "                cv2.drawContours(mask_roi, [cnt], -1, 255, -1)\n",
    "                mean_hsv = cv2.mean(hsv, mask=mask_roi)[:3]\n",
    "                for lower, upper, color_name in color_ranges:\n",
    "                    if np.all(lower <= mean_hsv) and np.all(mean_hsv <= upper):\n",
    "                        cv2.rectangle(frame, (x + obstacle_crop_margin, y),\n",
    "                                      (x + w + obstacle_crop_margin, y + h), (0, 0, 255), 2)\n",
    "                        cv2.putText(frame, f\"Obstacle: {color_name}\",\n",
    "                                    (x + obstacle_crop_margin, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6,\n",
    "                                    (0, 0, 255), 2)\n",
    "                        return True\n",
    "    return False\n",
    "\n",
    "# -------------------- Main Function --------------------\n",
    "\n",
    "def main(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return\n",
    "\n",
    "    lane_state_machine = LaneStateMachine(stability_threshold=5)\n",
    "    crop_margin = 144  # 15% of 960\n",
    "    obstacle_crop_margin = 336  # 35% of 960\n",
    "\n",
    "    prev_time, frame_count, fps = time.time(), 0, 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.resize(frame, (960, 540))\n",
    "        height, width = frame.shape[:2]\n",
    "\n",
    "        # Lane Detection\n",
    "        lane_mask, edges, lines, lane_roi = detect_lanes(frame, crop_margin)\n",
    "        left_lines, right_lines = classify_lane_lines(lines, crop_margin, height)\n",
    "        left_dashed = is_dashed(left_lines)\n",
    "        right_dashed = is_dashed(right_lines)\n",
    "        lane_overlay = draw_lane_lines(frame, left_lines, right_lines)\n",
    "\n",
    "        # Obstacle Detection\n",
    "        obstacle_detected = detect_obstacles(frame, obstacle_crop_margin)\n",
    "\n",
    "        # Decision Making\n",
    "        if obstacle_detected:\n",
    "            current_decision = \"STOP - Obstacle Ahead\"\n",
    "        elif right_dashed and not left_dashed:\n",
    "            current_decision = \"Right Turn Possible – Dashed Line\"\n",
    "        elif left_dashed and not right_dashed:\n",
    "            current_decision = \"Left Turn Possible – Dashed Line\"\n",
    "        elif not left_lines and not right_lines:\n",
    "            current_decision = \"No Lane Detected\"\n",
    "        else:\n",
    "            current_decision = \"Go Straight\"\n",
    "\n",
    "        decision = lane_state_machine.update(current_decision)\n",
    "\n",
    "        # Overlay display\n",
    "        combined_lower = cv2.addWeighted(lane_roi, 0.7, cv2.cvtColor(lane_mask, cv2.COLOR_GRAY2BGR), 0.3, 0)\n",
    "        combined_lower = cv2.addWeighted(combined_lower, 0.9, cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR), 0.4, 0)\n",
    "        full_frame = frame.copy()\n",
    "        full_frame[height // 2:, crop_margin:width - crop_margin] = combined_lower\n",
    "        output = cv2.addWeighted(full_frame, 1, lane_overlay, 0.6, 0)\n",
    "\n",
    "        cv2.rectangle(output, (20, 20), (620, 80), (0, 0, 0), -1)\n",
    "        cv2.putText(output, decision, (30, 65), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count >= 10:\n",
    "            curr_time = time.time()\n",
    "            fps = frame_count / (curr_time - prev_time)\n",
    "            prev_time = curr_time\n",
    "            frame_count = 0\n",
    "\n",
    "        cv2.putText(output, f\"FPS: {fps:.2f}\", (700, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Show windows\n",
    "        cv2.imshow('Original Frame', frame)\n",
    "        cv2.imshow('Lane Area', lane_overlay)\n",
    "        cv2.imshow('Final Output', output)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# -------------------- Run --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main(\"PXL_20250325_044505516.TS.mp4\")"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T17:03:01.487318Z",
     "start_time": "2025-05-12T17:02:58.104449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# -------------------- Lane State Machine Class --------------------\n",
    "class LaneStateMachine:\n",
    "    def __init__(self, stability_threshold=5):\n",
    "        self.state = \"No Lane Detected\"\n",
    "        self.counters = defaultdict(int)\n",
    "        self.threshold = stability_threshold\n",
    "\n",
    "    def update(self, new_state):\n",
    "        for key in self.counters:\n",
    "            if key != new_state:\n",
    "                self.counters[key] = 0\n",
    "        self.counters[new_state] += 1\n",
    "\n",
    "        if self.counters[new_state] >= self.threshold:\n",
    "            if new_state != self.state:\n",
    "                self.state = new_state\n",
    "                for key in self.counters:\n",
    "                    self.counters[key] = 0\n",
    "        return self.state\n",
    "\n",
    "# -------------------- Utility Functions --------------------\n",
    "def apply_clahe(image):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    cl = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8)).apply(l)\n",
    "    return cv2.cvtColor(cv2.merge((cl, a, b)), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def detect_lanes(frame, crop_margin):\n",
    "    height, width = frame.shape[:2]\n",
    "    roi = frame[height // 2:, crop_margin:width - crop_margin]\n",
    "\n",
    "    # Apply CLAHE for contrast enhancement\n",
    "    clahe_roi = apply_clahe(roi)\n",
    "\n",
    "    # HSV yellow mask with tightened thresholds to reduce grass\n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    # Bright yellow filtering\n",
    "    hsv_yellow_mask = cv2.inRange(hsv, np.array([20, 100, 100]), np.array([35, 255, 255]))\n",
    "    v_mask = cv2.inRange(v, 150, 255)\n",
    "    hsv_yellow_mask = cv2.bitwise_and(hsv_yellow_mask, hsv_yellow_mask, mask=v_mask)\n",
    "\n",
    "    # LAB yellow mask (optional but helps in poor lighting)\n",
    "    lab = cv2.cvtColor(roi, cv2.COLOR_BGR2LAB)\n",
    "    lab_yellow_mask = cv2.inRange(lab, np.array([150, 120, 120]), np.array([255, 160, 160]))\n",
    "\n",
    "    # Combine HSV + LAB masks\n",
    "    combined_mask = cv2.bitwise_or(hsv_yellow_mask, lab_yellow_mask)\n",
    "\n",
    "    # Morphological filtering to suppress grass textures\n",
    "    kernel = np.ones((7, 7), np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Edge detection on masked bright yellow lane area\n",
    "    masked_roi = cv2.bitwise_and(clahe_roi, clahe_roi, mask=combined_mask)\n",
    "    gray = cv2.cvtColor(masked_roi, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blur, 100, 200)\n",
    "    edges = cv2.bitwise_and(edges, combined_mask)\n",
    "\n",
    "    # Detect lines\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=50, minLineLength=50, maxLineGap=30)\n",
    "    return combined_mask, edges, lines, roi\n",
    "\n",
    "def classify_lane_lines(lines, crop_margin, height):\n",
    "    left_lines, right_lines = [], []\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            x1 += crop_margin\n",
    "            x2 += crop_margin\n",
    "            y1 += height // 2\n",
    "            y2 += height // 2\n",
    "\n",
    "            if x2 - x1 == 0:\n",
    "                continue\n",
    "\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "            angle = np.degrees(np.arctan(abs(slope)))\n",
    "\n",
    "            # Only consider lines within specific angle ranges\n",
    "            if 30 < angle < 80:  # Typical lane angles\n",
    "                if slope < 0:\n",
    "                    left_lines.extend([(x1, y1), (x2, y2)])\n",
    "                else:\n",
    "                    right_lines.extend([(x1, y1), (x2, y2)])\n",
    "    return left_lines, right_lines\n",
    "\n",
    "def draw_lane_lines(frame, left_lines, right_lines):\n",
    "    height = frame.shape[0]\n",
    "    plot_y = np.linspace(height // 2, height - 1, num=height // 2)\n",
    "    line_image = np.zeros_like(frame)\n",
    "\n",
    "    def draw_line(points, color):\n",
    "        if points:\n",
    "            points_np = np.array(points)\n",
    "            fit = np.polyfit(points_np[:, 1], points_np[:, 0], 1)\n",
    "            x_vals = fit[0] * plot_y + fit[1]\n",
    "            for x, y in zip(x_vals, plot_y):\n",
    "                cv2.circle(line_image, (int(x), int(y)), 2, color, -1)\n",
    "\n",
    "    draw_line(left_lines, (255, 0, 0))\n",
    "    draw_line(right_lines, (0, 0, 255))\n",
    "    return line_image\n",
    "\n",
    "# -------------------- Object Detection within Shaded Region --------------------\n",
    "\n",
    "def detect_objects_in_shaded_region(road_mask, frame):\n",
    "    # Find contours in the road mask (Shaded area)\n",
    "    contours, _ = cv2.findContours(road_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter out small contours (noise)\n",
    "    large_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 1000]  # Adjust the area threshold\n",
    "\n",
    "    # Get road boundaries\n",
    "    height, width = frame.shape[:2]\n",
    "    road_y_start = height // 2\n",
    "    road_y_end = height\n",
    "\n",
    "    # Draw bounding boxes around detected objects, constrained within the road area\n",
    "    result_frame = frame.copy()\n",
    "    for cnt in large_contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "        # Ensure the bounding box is constrained within the road area\n",
    "        if y + h <= road_y_end and y >= road_y_start:\n",
    "            # Adjust bounding box to be centered horizontally and placed at the bottom\n",
    "            center_x = (frame.shape[1] // 2) - (w // 2)  # Centered horizontally\n",
    "            center_y = road_y_end - h  # Placed at the bottom vertically\n",
    "\n",
    "            # Draw the bounding box at the shifted coordinates\n",
    "            cv2.rectangle(result_frame, (center_x, center_y), (center_x + w, center_y + h), (0, 255, 0), 2)  # Green bounding boxes\n",
    "\n",
    "    return result_frame, large_contours\n",
    "\n",
    "def main(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return\n",
    "\n",
    "    lane_state_machine = LaneStateMachine(stability_threshold=5)\n",
    "    crop_margin = 144  # 15% of 960\n",
    "    obstacle_crop_margin = 336  # 35% of 960\n",
    "\n",
    "    prev_time, frame_count, fps = time.time(), 0, 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.resize(frame, (960, 540))\n",
    "        height, width = frame.shape[:2]\n",
    "\n",
    "        # Lane Detection\n",
    "        lane_mask, edges, lines, lane_roi = detect_lanes(frame, crop_margin)\n",
    "        left_lines, right_lines = classify_lane_lines(lines, crop_margin, height)\n",
    "        left_dashed = is_dashed(left_lines)\n",
    "        right_dashed = is_dashed(right_lines)\n",
    "        lane_overlay = draw_lane_lines(frame, left_lines, right_lines)\n",
    "\n",
    "        # Object Detection within Shaded Yellow Region (Road)\n",
    "        detected_frame, large_contours = detect_objects_in_shaded_region(lane_mask, frame)\n",
    "\n",
    "        # Decision Making\n",
    "        if large_contours:\n",
    "            current_decision = \"STOP - Obstacle Ahead\"\n",
    "        elif right_dashed and not left_dashed:\n",
    "            current_decision = \"Right Turn Possible – Dashed Line\"\n",
    "        elif left_dashed and not right_dashed:\n",
    "            current_decision = \"Left Turn Possible – Dashed Line\"\n",
    "        elif not left_lines and not right_lines:\n",
    "            current_decision = \"No Lane Detected\"\n",
    "        else:\n",
    "            current_decision = \"Go Straight\"\n",
    "\n",
    "        decision = lane_state_machine.update(current_decision)\n",
    "\n",
    "        # Overlay display\n",
    "        combined_lower = cv2.addWeighted(lane_roi, 0.7, cv2.cvtColor(lane_mask, cv2.COLOR_GRAY2BGR), 0.3, 0)\n",
    "        combined_lower = cv2.addWeighted(combined_lower, 0.9, cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR), 0.4, 0)\n",
    "        full_frame = frame.copy()\n",
    "        full_frame[height // 2:, crop_margin:width - crop_margin] = combined_lower\n",
    "        output = cv2.addWeighted(full_frame, 1, lane_overlay, 0.6, 0)\n",
    "\n",
    "        cv2.rectangle(output, (20, 20), (620, 80), (0, 0, 0), -1)\n",
    "        cv2.putText(output, decision, (30, 65), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count >= 10:\n",
    "            curr_time = time.time()\n",
    "            fps = frame_count / (curr_time - prev_time)\n",
    "            prev_time = curr_time\n",
    "            frame_count = 0\n",
    "\n",
    "        cv2.putText(output, f\"FPS: {fps:.2f}\", (700, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Show windows\n",
    "        cv2.imshow('Original Frame', frame)\n",
    "        cv2.imshow('Lane Area', lane_overlay)\n",
    "        cv2.imshow('Final Output', output)\n",
    "        cv2.imshow(\"Detected Objects\", detected_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(\"PXL_20250325_043754655.TS.mp4\")  # Update the video path\n"
   ],
   "id": "eeeaa8ac3a97ca2d",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'is_dashed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 222\u001B[39m\n\u001B[32m    220\u001B[39m \u001B[38;5;66;03m# -------------------- Run --------------------\u001B[39;00m\n\u001B[32m    221\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[34m__name__\u001B[39m == \u001B[33m\"\u001B[39m\u001B[33m__main__\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m222\u001B[39m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mPXL_20250325_043754655.TS.mp4\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Update the video path\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 168\u001B[39m, in \u001B[36mmain\u001B[39m\u001B[34m(video_path)\u001B[39m\n\u001B[32m    166\u001B[39m lane_mask, edges, lines, lane_roi = detect_lanes(frame, crop_margin)\n\u001B[32m    167\u001B[39m left_lines, right_lines = classify_lane_lines(lines, crop_margin, height)\n\u001B[32m--> \u001B[39m\u001B[32m168\u001B[39m left_dashed = \u001B[43mis_dashed\u001B[49m(left_lines)\n\u001B[32m    169\u001B[39m right_dashed = is_dashed(right_lines)\n\u001B[32m    170\u001B[39m lane_overlay = draw_lane_lines(frame, left_lines, right_lines)\n",
      "\u001B[31mNameError\u001B[39m: name 'is_dashed' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T18:53:45.340669Z",
     "start_time": "2025-05-10T18:52:54.381192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_obstacles(frame, obstacle_crop_margin):\n",
    "    height, width = frame.shape[:2]\n",
    "    hsv = cv2.cvtColor(frame[:, obstacle_crop_margin:width - obstacle_crop_margin], cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    color_ranges = [\n",
    "        (np.array([0, 0, 0]), np.array([180, 255, 50]), 'Black'),\n",
    "        (np.array([90, 50, 50]), np.array([130, 255, 255]), 'Blue'),\n",
    "        (np.array([0, 70, 50]), np.array([10, 255, 255]), 'Red'),\n",
    "        (np.array([160, 70, 50]), np.array([180, 255, 255]), 'Red')\n",
    "    ]\n",
    "\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    combined_mask = np.zeros_like(hsv[:, :, 0])\n",
    "    color_mask_map = []\n",
    "\n",
    "    for lower, upper, color_name in color_ranges:\n",
    "        mask = cv2.inRange(hsv, lower, upper)\n",
    "        color_mask_map.append((mask, color_name))\n",
    "        combined_mask = cv2.bitwise_or(combined_mask, mask)\n",
    "\n",
    "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if 500 < area < 750:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            center_x_global = x + w // 2 + obstacle_crop_margin\n",
    "            if width // 4 < center_x_global < 3 * width // 4:\n",
    "                mask_roi = np.zeros_like(combined_mask)\n",
    "                cv2.drawContours(mask_roi, [cnt], -1, 255, -1)\n",
    "                mean_hsv = cv2.mean(hsv, mask=mask_roi)[:3]\n",
    "                for lower, upper, color_name in color_ranges:\n",
    "                    if np.all(lower <= mean_hsv) and np.all(mean_hsv <= upper):\n",
    "                        cv2.rectangle(frame, (x + obstacle_crop_margin, y),\n",
    "                                      (x + w + obstacle_crop_margin, y + h), (0, 0, 255), 2)\n",
    "                        cv2.putText(frame, f\"Obstacle: {color_name}\",\n",
    "                                    (x + obstacle_crop_margin, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6,\n",
    "                                    (0, 0, 255), 2)\n",
    "                        return True\n",
    "    return False\n",
    "\n",
    "def band_pass_thresholding_and_detection(image, lower_bound, upper_bound, min_area=1000):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, lower_mask = cv2.threshold(gray, lower_bound[0], upper_bound[0], cv2.THRESH_BINARY)\n",
    "    _, upper_mask = cv2.threshold(gray, lower_bound[1], upper_bound[1], cv2.THRESH_BINARY_INV)\n",
    "    road_mask = cv2.bitwise_and(lower_mask, upper_mask)\n",
    "    contours, _ = cv2.findContours(road_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    large_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_area]\n",
    "    result_image = image.copy()\n",
    "    for cnt in large_contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(result_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    return result_image, road_mask\n",
    "\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file {video_path}\")\n",
    "        return\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_resized = cv2.resize(frame, (960, 540))\n",
    "\n",
    "        # Apply the band-pass thresholding\n",
    "        processed_frame, road_mask = band_pass_thresholding_and_detection(frame_resized, lower_bound=(120, 130), upper_bound=(200, 210))\n",
    "\n",
    "        # Apply the obstacle detection\n",
    "        obstacle_detected = detect_obstacles(frame_resized, obstacle_crop_margin=336)\n",
    "        decision = \"Go Straight\"  # Default decision\n",
    "        if obstacle_detected:\n",
    "            decision = \"STOP - Obstacle Ahead\"\n",
    "\n",
    "        # Display decision on frame\n",
    "        cv2.rectangle(processed_frame, (20, 20), (620, 80), (0, 0, 0), -1)\n",
    "        cv2.putText(processed_frame, decision, (30, 65), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)\n",
    "\n",
    "        # Show the processed frame with decision\n",
    "        cv2.imshow('Processed Video', processed_frame)\n",
    "\n",
    "        # Exit condition\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "process_video(\"PXL_20250325_043754655.TS.mp4\")"
   ],
   "id": "8cc152a305f55261",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T19:16:14.790068Z",
     "start_time": "2025-05-10T19:16:03.198592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# -------------------- Lane State Machine Class --------------------\n",
    "\n",
    "class LaneStateMachine:\n",
    "    def __init__(self, stability_threshold=5):\n",
    "        self.state = \"No Lane Detected\"\n",
    "        self.counters = defaultdict(int)\n",
    "        self.threshold = stability_threshold\n",
    "\n",
    "    def update(self, new_state):\n",
    "        for key in self.counters:\n",
    "            if key != new_state:\n",
    "                self.counters[key] = 0\n",
    "        self.counters[new_state] += 1\n",
    "\n",
    "        if self.counters[new_state] >= self.threshold:\n",
    "            if new_state != self.state:\n",
    "                self.state = new_state\n",
    "                for key in self.counters:\n",
    "                    self.counters[key] = 0\n",
    "        return self.state\n",
    "\n",
    "# -------------------- Utility Functions --------------------\n",
    "\n",
    "def apply_clahe(image):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    cl = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8)).apply(l)\n",
    "    return cv2.cvtColor(cv2.merge((cl, a, b)), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def detect_lanes(frame, crop_margin):\n",
    "    height, width = frame.shape[:2]\n",
    "    roi = frame[height // 2:, crop_margin:width - crop_margin]\n",
    "\n",
    "    # Apply CLAHE for contrast enhancement\n",
    "    clahe_roi = apply_clahe(roi)\n",
    "\n",
    "    # HSV yellow mask with tightened thresholds to reduce grass\n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    # Bright yellow filtering\n",
    "    hsv_yellow_mask = cv2.inRange(hsv, np.array([20, 100, 100]), np.array([35, 255, 255]))\n",
    "    v_mask = cv2.inRange(v, 150, 255)\n",
    "    hsv_yellow_mask = cv2.bitwise_and(hsv_yellow_mask, hsv_yellow_mask, mask=v_mask)\n",
    "\n",
    "    # LAB yellow mask (optional but helps in poor lighting)\n",
    "    lab = cv2.cvtColor(roi, cv2.COLOR_BGR2LAB)\n",
    "    lab_yellow_mask = cv2.inRange(lab, np.array([150, 120, 120]), np.array([255, 160, 160]))\n",
    "\n",
    "    # Combine HSV + LAB masks\n",
    "    combined_mask = cv2.bitwise_or(hsv_yellow_mask, lab_yellow_mask)\n",
    "\n",
    "    # Morphological filtering to suppress grass textures\n",
    "    kernel = np.ones((7, 7), np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Edge detection on masked bright yellow lane area\n",
    "    masked_roi = cv2.bitwise_and(clahe_roi, clahe_roi, mask=combined_mask)\n",
    "    gray = cv2.cvtColor(masked_roi, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blur, 100, 200)\n",
    "    edges = cv2.bitwise_and(edges, combined_mask)\n",
    "\n",
    "    # Detect lines\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=50, minLineLength=50, maxLineGap=30)\n",
    "    return combined_mask, edges, lines, roi\n",
    "\n",
    "def classify_lane_lines(lines, crop_margin, height):\n",
    "    left_lines, right_lines = [], []\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            x1 += crop_margin\n",
    "            x2 += crop_margin\n",
    "            y1 += height // 2\n",
    "            y2 += height // 2\n",
    "\n",
    "            if x2 - x1 == 0:\n",
    "                continue\n",
    "\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "            angle = np.degrees(np.arctan(abs(slope)))\n",
    "\n",
    "            # Only consider lines within specific angle ranges\n",
    "            if 30 < angle < 80:  # Typical lane angles\n",
    "                if slope < 0:\n",
    "                    left_lines.extend([(x1, y1), (x2, y2)])\n",
    "                else:\n",
    "                    right_lines.extend([(x1, y1), (x2, y2)])\n",
    "    return left_lines, right_lines\n",
    "\n",
    "def draw_lane_lines(frame, left_lines, right_lines):\n",
    "    height = frame.shape[0]\n",
    "    plot_y = np.linspace(height // 2, height - 1, num=height // 2)\n",
    "    line_image = np.zeros_like(frame)\n",
    "\n",
    "    def draw_line(points, color):\n",
    "        if points:\n",
    "            points_np = np.array(points)\n",
    "            fit = np.polyfit(points_np[:, 1], points_np[:, 0], 1)\n",
    "            x_vals = fit[0] * plot_y + fit[1]\n",
    "            for x, y in zip(x_vals, plot_y):\n",
    "                cv2.circle(line_image, (int(x), int(y)), 2, color, -1)\n",
    "\n",
    "    draw_line(left_lines, (255, 0, 0))\n",
    "    draw_line(right_lines, (0, 0, 255))\n",
    "    return line_image\n",
    "\n",
    "# Define the improved road mask and object detection function\n",
    "def road_mask_and_detect(frame, lower_bound=(120, 130), upper_bound=(200, 210), min_area=1000):\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply the road mask based on thresholds\n",
    "    _, lower_mask = cv2.threshold(gray, lower_bound[0], upper_bound[0], cv2.THRESH_BINARY)\n",
    "    _, upper_mask = cv2.threshold(gray, lower_bound[1], upper_bound[1], cv2.THRESH_BINARY_INV)\n",
    "    road_mask = cv2.bitwise_and(lower_mask, upper_mask)\n",
    "\n",
    "    # Find contours in the road mask\n",
    "    contours, _ = cv2.findContours(road_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter based on size (min_area)\n",
    "    large_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_area]\n",
    "\n",
    "    # Draw bounding boxes around detected obstacles on the road\n",
    "    result_image = frame.copy()\n",
    "    for cnt in large_contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(result_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    return result_image, road_mask\n",
    "\n",
    "# -------------------- Main Function --------------------\n",
    "\n",
    "def main(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return\n",
    "\n",
    "    lane_state_machine = LaneStateMachine(stability_threshold=5)\n",
    "    crop_margin = 144  # 15% of 960\n",
    "    obstacle_crop_margin = 336  # 35% of 960\n",
    "\n",
    "    prev_time, frame_count, fps = time.time(), 0, 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.resize(frame, (960, 540))\n",
    "        height, width = frame.shape[:2]\n",
    "\n",
    "        # Lane Detection\n",
    "        lane_mask, edges, lines, lane_roi = detect_lanes(frame, crop_margin)\n",
    "        left_lines, right_lines = classify_lane_lines(lines, crop_margin, height)\n",
    "        left_dashed = is_dashed(left_lines)\n",
    "        right_dashed = is_dashed(right_lines)\n",
    "        lane_overlay = draw_lane_lines(frame, left_lines, right_lines)\n",
    "\n",
    "        # Apply road mask and detect objects\n",
    "        processed_frame, road_mask = road_mask_and_detect(frame)\n",
    "\n",
    "        # Decision Making\n",
    "        decision = \"Go Straight\"  # Default decision\n",
    "        obstacle_detected = False  # Placeholder; apply your detection condition here\n",
    "\n",
    "        if obstacle_detected:\n",
    "            decision = \"STOP - Obstacle Ahead\"\n",
    "        elif right_dashed and not left_dashed:\n",
    "            decision = \"Right Turn Possible – Dashed Line\"\n",
    "        elif left_dashed and not right_dashed:\n",
    "            decision = \"Left Turn Possible – Dashed Line\"\n",
    "        elif not left_lines and not right_lines:\n",
    "            decision = \"No Lane Detected\"\n",
    "\n",
    "        # Overlay display\n",
    "        cv2.rectangle(processed_frame, (20, 20), (620, 80), (0, 0, 0), -1)  # Background for text\n",
    "        cv2.putText(processed_frame, decision, (30, 65), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)\n",
    "\n",
    "        # Show the final video output\n",
    "        cv2.imshow('Processed Video', processed_frame)\n",
    "\n",
    "        # Stop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# -------------------- Run --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main(\"PXL_20250325_043754655.TS.mp4\")  # Adjust path as needed\n"
   ],
   "id": "653b61a810f0020d",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T19:07:16.342853Z",
     "start_time": "2025-05-10T19:06:14.980193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# -------------------- Lane State Machine Class --------------------\n",
    "\n",
    "class LaneStateMachine:\n",
    "    def __init__(self, stability_threshold=5):\n",
    "        self.state = \"No Lane Detected\"\n",
    "        self.counters = defaultdict(int)\n",
    "        self.threshold = stability_threshold\n",
    "\n",
    "    def update(self, new_state):\n",
    "        for key in self.counters:\n",
    "            if key != new_state:\n",
    "                self.counters[key] = 0\n",
    "        self.counters[new_state] += 1\n",
    "\n",
    "        if self.counters[new_state] >= self.threshold:\n",
    "            if new_state != self.state:\n",
    "                self.state = new_state\n",
    "                for key in self.counters:\n",
    "                    self.counters[key] = 0\n",
    "        return self.state\n",
    "\n",
    "# -------------------- Utility Functions --------------------\n",
    "\n",
    "def apply_clahe(image):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    cl = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8)).apply(l)\n",
    "    return cv2.cvtColor(cv2.merge((cl, a, b)), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def detect_lanes(frame, crop_margin_percent):\n",
    "    height, width = frame.shape[:2]\n",
    "    crop_margin_x = int(width * crop_margin_percent)\n",
    "    crop_margin_y = int(height * 0.5)  # Half of the height for the ROI\n",
    "\n",
    "    roi = frame[crop_margin_y:, crop_margin_x:width - crop_margin_x]\n",
    "\n",
    "    # Apply CLAHE for contrast enhancement\n",
    "    clahe_roi = apply_clahe(roi)\n",
    "\n",
    "    # HSV yellow mask with tightened thresholds to reduce grass\n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    # Bright yellow filtering\n",
    "    hsv_yellow_mask = cv2.inRange(hsv, np.array([20, 100, 100]), np.array([35, 255, 255]))\n",
    "    v_mask = cv2.inRange(v, 150, 255)\n",
    "    hsv_yellow_mask = cv2.bitwise_and(hsv_yellow_mask, hsv_yellow_mask, mask=v_mask)\n",
    "\n",
    "    # LAB yellow mask\n",
    "    lab = cv2.cvtColor(roi, cv2.COLOR_BGR2LAB)\n",
    "    lab_yellow_mask = cv2.inRange(lab, np.array([150, 120, 120]), np.array([255, 160, 160]))\n",
    "\n",
    "    # Combine HSV + LAB masks\n",
    "    combined_mask = cv2.bitwise_or(hsv_yellow_mask, lab_yellow_mask)\n",
    "\n",
    "    # Morphological filtering\n",
    "    kernel = np.ones((7, 7), np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Edge detection\n",
    "    masked_roi = cv2.bitwise_and(clahe_roi, clahe_roi, mask=combined_mask)\n",
    "    gray = cv2.cvtColor(masked_roi, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blur, 100, 200)\n",
    "    edges = cv2.bitwise_and(edges, combined_mask)\n",
    "\n",
    "    # Detect lines\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=50, minLineLength=50, maxLineGap=30)\n",
    "    return combined_mask, edges, lines, roi\n",
    "\n",
    "def classify_lane_lines(lines, crop_margin_percent, height):\n",
    "    left_lines, right_lines = [], []\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            x1 += int(crop_margin_percent * 960)\n",
    "            x2 += int(crop_margin_percent * 960)\n",
    "            y1 += height // 2\n",
    "            y2 += height // 2\n",
    "\n",
    "            if x2 - x1 == 0:\n",
    "                continue\n",
    "\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "            angle = np.degrees(np.arctan(abs(slope)))\n",
    "\n",
    "            if 30 < angle < 80:  # Typical lane angles\n",
    "                if slope < 0:\n",
    "                    left_lines.extend([(x1, y1), (x2, y2)])\n",
    "                else:\n",
    "                    right_lines.extend([(x1, y1), (x2, y2)])\n",
    "    return left_lines, right_lines\n",
    "\n",
    "def shade_lane_region(frame, left_lines, right_lines):\n",
    "    height = frame.shape[0]\n",
    "    overlay = np.zeros_like(frame)\n",
    "\n",
    "    if left_lines and right_lines:\n",
    "        left_points = np.array(left_lines).reshape(-1, 2)\n",
    "        right_points = np.array(right_lines).reshape(-1, 2)\n",
    "\n",
    "        left_fit = np.polyfit(left_points[:, 1], left_points[:, 0], 1)\n",
    "        right_fit = np.polyfit(right_points[:, 1], right_points[:, 0], 1)\n",
    "\n",
    "        plot_y = np.linspace(height // 2, height - 1, num=height // 2)\n",
    "        left_x = left_fit[0] * plot_y + left_fit[1]\n",
    "        right_x = right_fit[0] * plot_y + right_fit[1]\n",
    "\n",
    "        pts_left = np.array([np.transpose(np.vstack([left_x, plot_y]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_x, plot_y])))])\n",
    "        pts = np.hstack((pts_left, pts_right)).astype(np.int32)\n",
    "\n",
    "        cv2.fillPoly(overlay, [pts], (0, 255, 255))  # Yellow fill\n",
    "\n",
    "    return overlay\n",
    "\n",
    "# -------------------- Main Function --------------------\n",
    "\n",
    "def main(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return\n",
    "\n",
    "    lane_state_machine = LaneStateMachine(stability_threshold=5)\n",
    "    crop_margin_percent = 0.2 # 15% of width for left/right cropping\n",
    "    obstacle_crop_margin_percent = 0.35  # 35% for obstacle detection cropping\n",
    "\n",
    "    prev_time, frame_count, fps = time.time(), 0, 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.resize(frame, (960, 540))\n",
    "        height, width = frame.shape[:2]\n",
    "\n",
    "        # Lane Detection\n",
    "        lane_mask, edges, lines, lane_roi = detect_lanes(frame, crop_margin_percent)\n",
    "        left_lines, right_lines = classify_lane_lines(lines, crop_margin_percent, height)\n",
    "        lane_overlay = shade_lane_region(frame, left_lines, right_lines)\n",
    "\n",
    "        # Obstacle Detection (if required)\n",
    "        obstacle_detected = False  # Remove this function if not needed\n",
    "\n",
    "        # Decision Making\n",
    "        if obstacle_detected:\n",
    "            current_decision = \"STOP - Obstacle Ahead\"\n",
    "        elif not left_lines and not right_lines:\n",
    "            current_decision = \"No Lane Detected\"\n",
    "        else:\n",
    "            current_decision = \"Go Straight\"\n",
    "\n",
    "        decision = lane_state_machine.update(current_decision)\n",
    "\n",
    "        # Overlay display\n",
    "        combined_lower = cv2.addWeighted(lane_roi, 0.7, cv2.cvtColor(lane_mask, cv2.COLOR_GRAY2BGR), 0.3, 0)\n",
    "        combined_lower = cv2.addWeighted(combined_lower, 0.9, cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR), 0.4, 0)\n",
    "        full_frame = frame.copy()\n",
    "        full_frame[height // 2:, int(width * crop_margin_percent):width - int(width * crop_margin_percent)] = combined_lower\n",
    "        output = cv2.addWeighted(full_frame, 1, lane_overlay, 0.6, 0)\n",
    "        cv2.rectangle(output, (20, 20), (620, 80), (0, 0, 0), -1)\n",
    "        cv2.putText(output, decision, (30, 65), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count >= 10:\n",
    "            curr_time = time.time()\n",
    "            fps = frame_count / (curr_time - prev_time)\n",
    "            prev_time = curr_time\n",
    "            frame_count = 0\n",
    "\n",
    "        cv2.putText(output, f\"FPS: {fps:.2f}\", (700, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Show windows\n",
    "        cv2.imshow('Original Frame', frame)\n",
    "        cv2.imshow('Lane Area', lane_overlay)\n",
    "        cv2.imshow('Final Output', output)\n",
    "        cv2.imshow(\"Canny Edge Output\",edges)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"PXL_20250325_043754655.TS.mp4\"  # Update the video path\n",
    "    main(video_path)"
   ],
   "id": "82aa999ffb4b0601",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T19:14:40.502158Z",
     "start_time": "2025-05-10T19:13:46.087396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the function to create the mask for the road area\n",
    "def create_road_mask(frame, lower_bound=(120, 130), upper_bound=(200, 210)):\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply the band-pass thresholding approach\n",
    "    _, lower_mask = cv2.threshold(gray, lower_bound[0], upper_bound[0], cv2.THRESH_BINARY)\n",
    "    _, upper_mask = cv2.threshold(gray, lower_bound[1], upper_bound[1], cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Create the road mask\n",
    "    road_mask = cv2.bitwise_and(lower_mask, upper_mask)\n",
    "\n",
    "    return road_mask\n",
    "\n",
    "# Function to perform Connected Component Analysis (CCA) to detect objects in the road mask\n",
    "def detect_objects_in_road_mask(road_mask):\n",
    "    # Find contours from the road mask (Connected Component Analysis)\n",
    "    contours, _ = cv2.findContours(road_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter the contours based on the area (to ignore noise)\n",
    "    large_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 1000]  # Adjust threshold as needed\n",
    "\n",
    "    return large_contours\n",
    "\n",
    "# Function to apply CCA, detect objects, and draw bounding boxes\n",
    "def process_frame_and_detect_objects(frame):\n",
    "    # Create the road mask\n",
    "    road_mask = create_road_mask(frame)\n",
    "\n",
    "    # Perform CCA to detect objects in the road region\n",
    "    large_contours = detect_objects_in_road_mask(road_mask)\n",
    "\n",
    "    # Draw bounding boxes around detected objects\n",
    "    result_frame = frame.copy()\n",
    "    for cnt in large_contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(result_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Green bounding boxes\n",
    "\n",
    "    return result_frame, road_mask\n",
    "\n",
    "# Open the video and process it\n",
    "video_path = \"PXL_20250325_043754655.TS.mp4\"  # Replace with your video path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "else:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Resize frame for processing\n",
    "        frame_resized = cv2.resize(frame, (960, 540))\n",
    "\n",
    "        # Process the frame and detect objects in the road region\n",
    "        processed_frame, road_mask = process_frame_and_detect_objects(frame_resized)\n",
    "\n",
    "        # Display the processed frame with bounding boxes\n",
    "        cv2.imshow('Processed Frame', processed_frame)\n",
    "\n",
    "        # Exit if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release the video capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "d27e98811109b4b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "925608a2dc1c4c8a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
